{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3\n",
        "```\n",
        "CNN(\n",
        "  (layers): ModuleList(\n",
        "    (0): Sequential(\n",
        "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.2, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (1): Sequential(\n",
        "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.1, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "  )\n",
        "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "### Accuracy: 83.7429111531191 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UYZ8OLBDx-Ux"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip install --force-reinstall numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MuUh8kvMtkLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hts90WGtkLY",
        "outputId": "0102b394-fc01-477a-dfb8-23ce42550d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya existen datos de train, test y val.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = os.path.abspath('dataset_kagle/COVID-19_Radiography_Dataset')\n",
        "dest_dir = os.path.abspath('dataset')\n",
        "\n",
        "train_dir, test_dir, val_dir = utils.split_dataset(dataset_dir, dest_dir, test_ratio=0.2, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgR13YFtkLZ",
        "outputId": "2cc7afe9-7d53-4656-dd06-b4453a66bba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 14814\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4232\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_set =  torchvision.datasets.ImageFolder(train_dir, transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "test_set =  torchvision.datasets.ImageFolder(test_dir, transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_bKkikd4tkLZ"
      },
      "outputs": [],
      "source": [
        "tensor_img, label_idx = train_set[0]\n",
        "#utils.show_img(tensor_img, train_set.classes[label_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI64Ik9tkLZ"
      },
      "source": [
        "### Capa 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsPTz6ltkLa",
        "outputId": "3baac22a-aaa9-427f-ff78-317855f0c185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 1 **************************\n",
            "Dimensiones de entrada: 299 x 299\n",
            "Número de canales de entrada: 3\n",
            "Número de filtros: 32\n",
            "Dimensiones del kernel: 3 x 3\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 150 x 150\n",
            "Dimensiones luego del MaxPool2d: 75\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 1 **************************')\n",
        "layer1_in_channels, layer1_img_width, layer1_img_height = tensor_img.shape\n",
        "print(\"Dimensiones de entrada:\", layer1_img_width, \"x\", layer1_img_height)\n",
        "print(\"Número de canales de entrada:\", layer1_in_channels)\n",
        "\n",
        "layer1_num_filters = 32\n",
        "print(\"Número de filtros:\", layer1_num_filters)\n",
        "\n",
        "layer1_kernel_size = 3\n",
        "print(\"Dimensiones del kernel:\", layer1_kernel_size, \"x\", layer1_kernel_size)\n",
        "\n",
        "layer1_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer1_stride)\n",
        "\n",
        "layer1_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer1_padding)\n",
        "\n",
        "layer1_out_size = utils.size_output_layer(layer1_img_width, layer1_kernel_size, layer1_stride, layer1_padding)\n",
        "print(\"Dimensiones de salida:\", layer1_out_size, \"x\", layer1_out_size)\n",
        "\n",
        "layer1_output_dim = utils.size_output_layer(layer1_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer1_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUFBWQS4tkLb"
      },
      "outputs": [],
      "source": [
        "layer1_conv = nn.Conv2d(\n",
        "        layer1_in_channels,\n",
        "        layer1_num_filters,\n",
        "        layer1_kernel_size,\n",
        "        layer1_stride,\n",
        "        layer1_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpXwZfmtkLe"
      },
      "source": [
        "### Capa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxv5xj4tkLe",
        "outputId": "1dee455d-0be2-4738-c540-3f15b1375d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 2 **************************\n",
            "Dimensiones de entrada: 75 x 75\n",
            "Número de canales de entrada: 32\n",
            "Número de filtros: 64\n",
            "Dimensiones del kernel: 2 x 2\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 38 x 38\n",
            "Dimensiones luego del MaxPool2d: 19\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 2 **************************')\n",
        "layer2_in_channels, layer2_img_width, layer2_img_height = layer1_num_filters, layer1_output_dim, layer1_output_dim\n",
        "print(\"Dimensiones de entrada:\", layer2_img_width, \"x\", layer2_img_height)\n",
        "print(\"Número de canales de entrada:\", layer2_in_channels)\n",
        "\n",
        "layer2_num_filters = 64\n",
        "print(\"Número de filtros:\", layer2_num_filters)\n",
        "\n",
        "layer2_kernel_size = 2\n",
        "print(\"Dimensiones del kernel:\", layer2_kernel_size, \"x\", layer2_kernel_size)\n",
        "\n",
        "layer2_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer2_stride)\n",
        "\n",
        "layer2_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer2_padding)\n",
        "\n",
        "layer2_out_size = utils.size_output_layer(layer2_img_width, layer2_kernel_size, layer2_stride, layer2_padding)\n",
        "print(\"Dimensiones de salida:\", layer2_out_size, \"x\", layer2_out_size)\n",
        "\n",
        "layer2_output_dim = utils.size_output_layer(layer2_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer2_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1iKeohOJtkLf"
      },
      "outputs": [],
      "source": [
        "layer2_conv = nn.Conv2d(\n",
        "        layer2_in_channels,\n",
        "        layer2_num_filters,\n",
        "        layer2_kernel_size,\n",
        "        layer2_stride,\n",
        "        layer2_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS5CVeBtkLf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8XPq7tkLf",
        "outputId": "789c7a44-8915-44bf-a34c-fe7e870db5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.2, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 1: Convolutional layer\n",
        "layer1 = nn.Sequential(\n",
        "    layer1_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer1_num_filters),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWRAnEatkLg",
        "outputId": "78a6c547-200e-446e-b7cc-c7c84607f217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 2: Convolutional layer\n",
        "layer2 = nn.Sequential(\n",
        "    layer2_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer2_num_filters),\n",
        "    nn.Dropout(p=0.1),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WgzVKfCvtkLg"
      },
      "outputs": [],
      "source": [
        "# Layer 3: Linear Classifier\n",
        "num_classes = 4\n",
        "classifier = nn.Linear(\n",
        "    in_features=layer2_output_dim * layer2_output_dim * layer2_num_filters,\n",
        "    out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L-JabGrFtkLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.2, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = utils.CNN()\n",
        "\n",
        "model.addLayer(layer1)\n",
        "model.addLayer(layer2)\n",
        "\n",
        "model.addClassifier(classifier)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate =  0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXyqLR-otkLh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNv67NEjtkLh",
        "outputId": "85c72fc1-4459-48ea-a833-85fabf326971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch [1/10], Step [100/232], Loss: 1.5373\n",
            "Epoch [1/10], Step [200/232], Loss: 1.1944\n",
            "Epoch [2/10], Step [100/232], Loss: 0.4305\n",
            "Epoch [2/10], Step [200/232], Loss: 0.8912\n",
            "Epoch [3/10], Step [100/232], Loss: 0.9491\n",
            "Epoch [3/10], Step [200/232], Loss: 0.5109\n",
            "Epoch [4/10], Step [100/232], Loss: 0.1847\n",
            "Epoch [4/10], Step [200/232], Loss: 0.2979\n",
            "Epoch [5/10], Step [100/232], Loss: 0.3211\n",
            "Epoch [5/10], Step [200/232], Loss: 0.2682\n",
            "Epoch [6/10], Step [100/232], Loss: 0.2913\n",
            "Epoch [6/10], Step [200/232], Loss: 0.3944\n",
            "Epoch [7/10], Step [100/232], Loss: 0.1858\n",
            "Epoch [7/10], Step [200/232], Loss: 0.3196\n",
            "Epoch [8/10], Step [100/232], Loss: 0.1626\n",
            "Epoch [8/10], Step [200/232], Loss: 0.3134\n",
            "Epoch [9/10], Step [100/232], Loss: 0.1195\n",
            "Epoch [9/10], Step [200/232], Loss: 0.2991\n",
            "Epoch [10/10], Step [100/232], Loss: 0.1954\n",
            "Epoch [10/10], Step [200/232], Loss: 0.1641\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "list_loss= []\n",
        "list_time = []\n",
        "j=0\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # change the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_loss.append(loss.item())\n",
        "        list_time.append(j)\n",
        "        j+=1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "A8AyDkmBtkLh"
      },
      "outputs": [],
      "source": [
        "# for param in model.parameters():\n",
        "#     print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IWy5Pl4LtkLi",
        "outputId": "49d124ca-690f-42aa-8e65-ee54d31c980b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f42e5dc35d0>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(list_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Mymj_tkLi",
        "outputId": "d433f4d0-43ca-4439-a7d3-7c67643bf6dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 83.7429111531191 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "        t_outputs = model(t_images)\n",
        "        _, predicted = torch.max(t_outputs.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (predicted == t_labels).sum().item()\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto3_colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c836ea1838598e769062a9cf5fa60bfd2e0efc946eee0512711b4e28a236389"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
