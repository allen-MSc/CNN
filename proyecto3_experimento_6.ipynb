{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 6\n",
        "Applying **transforms.Normalize()** to Dataset\n",
        "```\n",
        "CNN(\n",
        "  (layers): ModuleList(\n",
        "    (0): Sequential(\n",
        "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (1): Sequential(\n",
        "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "  )\n",
        "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "### Accuracy: 84.26275992438563 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UYZ8OLBDx-Ux"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip install --force-reinstall numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MuUh8kvMtkLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hts90WGtkLY",
        "outputId": "6252eb58-6f18-4836-9ebc-7fd365424dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya existen datos de train, test y val.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = os.path.abspath('dataset_kagle/COVID-19_Radiography_Dataset')\n",
        "dest_dir = os.path.abspath('dataset')\n",
        "\n",
        "train_dir, test_dir, val_dir = utils.split_dataset(dataset_dir, dest_dir, test_ratio=0.2, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgR13YFtkLZ",
        "outputId": "b650babe-7074-4124-ef6d-3d7213aa4a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 14814\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4232\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_set =  torchvision.datasets.ImageFolder(\n",
        "    train_dir,\n",
        "    transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "test_set =  torchvision.datasets.ImageFolder(\n",
        "    test_dir,\n",
        "    transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_bKkikd4tkLZ"
      },
      "outputs": [],
      "source": [
        "tensor_img, label_idx = train_set[0]\n",
        "#utils.show_img(tensor_img, train_set.classes[label_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI64Ik9tkLZ"
      },
      "source": [
        "### Capa 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsPTz6ltkLa",
        "outputId": "95d8626f-4c65-4a3c-ce51-736dbedbab64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 1 **************************\n",
            "Dimensiones de entrada: 299 x 299\n",
            "Número de canales de entrada: 3\n",
            "Número de filtros: 32\n",
            "Dimensiones del kernel: 3 x 3\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 150 x 150\n",
            "Dimensiones luego del MaxPool2d: 75\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 1 **************************')\n",
        "layer1_in_channels, layer1_img_width, layer1_img_height = tensor_img.shape\n",
        "print(\"Dimensiones de entrada:\", layer1_img_width, \"x\", layer1_img_height)\n",
        "print(\"Número de canales de entrada:\", layer1_in_channels)\n",
        "\n",
        "layer1_num_filters = 32\n",
        "print(\"Número de filtros:\", layer1_num_filters)\n",
        "\n",
        "layer1_kernel_size = 3\n",
        "print(\"Dimensiones del kernel:\", layer1_kernel_size, \"x\", layer1_kernel_size)\n",
        "\n",
        "layer1_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer1_stride)\n",
        "\n",
        "layer1_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer1_padding)\n",
        "\n",
        "layer1_out_size = utils.size_output_layer(layer1_img_width, layer1_kernel_size, layer1_stride, layer1_padding)\n",
        "print(\"Dimensiones de salida:\", layer1_out_size, \"x\", layer1_out_size)\n",
        "\n",
        "layer1_output_dim = utils.size_output_layer(layer1_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer1_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUFBWQS4tkLb"
      },
      "outputs": [],
      "source": [
        "layer1_conv = nn.Conv2d(\n",
        "        layer1_in_channels,\n",
        "        layer1_num_filters,\n",
        "        layer1_kernel_size,\n",
        "        layer1_stride,\n",
        "        layer1_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpXwZfmtkLe"
      },
      "source": [
        "### Capa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxv5xj4tkLe",
        "outputId": "e2ab79ce-ba56-4685-ad17-13b9fcc84b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 2 **************************\n",
            "Dimensiones de entrada: 75 x 75\n",
            "Número de canales de entrada: 32\n",
            "Número de filtros: 64\n",
            "Dimensiones del kernel: 2 x 2\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 38 x 38\n",
            "Dimensiones luego del MaxPool2d: 19\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 2 **************************')\n",
        "layer2_in_channels, layer2_img_width, layer2_img_height = layer1_num_filters, layer1_output_dim, layer1_output_dim\n",
        "print(\"Dimensiones de entrada:\", layer2_img_width, \"x\", layer2_img_height)\n",
        "print(\"Número de canales de entrada:\", layer2_in_channels)\n",
        "\n",
        "layer2_num_filters = 64\n",
        "print(\"Número de filtros:\", layer2_num_filters)\n",
        "\n",
        "layer2_kernel_size = 2\n",
        "print(\"Dimensiones del kernel:\", layer2_kernel_size, \"x\", layer2_kernel_size)\n",
        "\n",
        "layer2_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer2_stride)\n",
        "\n",
        "layer2_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer2_padding)\n",
        "\n",
        "layer2_out_size = utils.size_output_layer(layer2_img_width, layer2_kernel_size, layer2_stride, layer2_padding)\n",
        "print(\"Dimensiones de salida:\", layer2_out_size, \"x\", layer2_out_size)\n",
        "\n",
        "layer2_output_dim = utils.size_output_layer(layer2_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer2_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iKeohOJtkLf"
      },
      "outputs": [],
      "source": [
        "layer2_conv = nn.Conv2d(\n",
        "        layer2_in_channels,\n",
        "        layer2_num_filters,\n",
        "        layer2_kernel_size,\n",
        "        layer2_stride,\n",
        "        layer2_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS5CVeBtkLf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8XPq7tkLf",
        "outputId": "6c83602f-13b1-47ce-86e5-cb86ba081a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 1: Convolutional layer\n",
        "layer1 = nn.Sequential(\n",
        "    layer1_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer1_num_filters),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWRAnEatkLg",
        "outputId": "13791e54-62b5-4e28-ceec-bdccdbaa030c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 2: Convolutional layer\n",
        "layer2 = nn.Sequential(\n",
        "    layer2_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer2_num_filters),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WgzVKfCvtkLg"
      },
      "outputs": [],
      "source": [
        "# Layer 3: Linear Classifier\n",
        "num_classes = 4\n",
        "classifier = nn.Linear(\n",
        "    in_features=layer2_output_dim * layer2_output_dim * layer2_num_filters,\n",
        "    out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L-JabGrFtkLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = utils.CNN()\n",
        "\n",
        "model.addLayer(layer1)\n",
        "model.addLayer(layer2)\n",
        "\n",
        "model.addClassifier(classifier)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate =  0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXyqLR-otkLh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNv67NEjtkLh",
        "outputId": "99cc7f55-5f10-4896-a5d0-8ab83e5edfec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch [1/10], Step [100/232], Loss: 0.5214\n",
            "Epoch [1/10], Step [200/232], Loss: 0.9885\n",
            "Epoch [2/10], Step [100/232], Loss: 0.6839\n",
            "Epoch [2/10], Step [200/232], Loss: 0.7950\n",
            "Epoch [3/10], Step [100/232], Loss: 0.4080\n",
            "Epoch [3/10], Step [200/232], Loss: 0.8013\n",
            "Epoch [4/10], Step [100/232], Loss: 0.6183\n",
            "Epoch [4/10], Step [200/232], Loss: 0.4962\n",
            "Epoch [5/10], Step [100/232], Loss: 0.2257\n",
            "Epoch [5/10], Step [200/232], Loss: 0.4103\n",
            "Epoch [6/10], Step [100/232], Loss: 0.3232\n",
            "Epoch [6/10], Step [200/232], Loss: 0.6128\n",
            "Epoch [7/10], Step [100/232], Loss: 0.3907\n",
            "Epoch [7/10], Step [200/232], Loss: 0.4645\n",
            "Epoch [8/10], Step [100/232], Loss: 0.4678\n",
            "Epoch [8/10], Step [200/232], Loss: 0.1512\n",
            "Epoch [9/10], Step [100/232], Loss: 0.0686\n",
            "Epoch [9/10], Step [200/232], Loss: 0.2743\n",
            "Epoch [10/10], Step [100/232], Loss: 0.0574\n",
            "Epoch [10/10], Step [200/232], Loss: 0.1343\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "list_loss= []\n",
        "list_time = []\n",
        "j=0\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # change the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_loss.append(loss.item())\n",
        "        list_time.append(j)\n",
        "        j+=1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "IWy5Pl4LtkLi",
        "outputId": "512c8b90-e535-4c98-991d-8cb0ccb7cbc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3f7a6202d0>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(list_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Mymj_tkLi",
        "outputId": "e5de6457-9949-43c1-fded-e8bbe472c400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 84.26275992438563 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "        t_outputs = model(t_images)\n",
        "        _, predicted = torch.max(t_outputs.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (predicted == t_labels).sum().item()\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c836ea1838598e769062a9cf5fa60bfd2e0efc946eee0512711b4e28a236389"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
