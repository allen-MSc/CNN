{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 7\n",
        "Applying **transforms.Normalize()** to Dataset\n",
        "```\n",
        "CNN(\n",
        "  (layers): ModuleList(\n",
        "    (0): Sequential(\n",
        "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.2, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (1): Sequential(\n",
        "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.1, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "  )\n",
        "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "### Accuracy: 86.10586011342156 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UYZ8OLBDx-Ux"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip install --force-reinstall numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MuUh8kvMtkLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hts90WGtkLY",
        "outputId": "f79d411f-24f2-4de7-936d-a690be044fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya existen datos de train, test y val.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = os.path.abspath('dataset_kagle/COVID-19_Radiography_Dataset')\n",
        "dest_dir = os.path.abspath('dataset')\n",
        "\n",
        "train_dir, test_dir, val_dir = utils.split_dataset(dataset_dir, dest_dir, test_ratio=0.2, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgR13YFtkLZ",
        "outputId": "d01ae7c7-bec2-4459-f767-3811399ed583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 14814\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4232\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_set =  torchvision.datasets.ImageFolder(\n",
        "    train_dir,\n",
        "    transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "test_set =  torchvision.datasets.ImageFolder(\n",
        "    test_dir,\n",
        "    transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_bKkikd4tkLZ"
      },
      "outputs": [],
      "source": [
        "tensor_img, label_idx = train_set[0]\n",
        "#utils.show_img(tensor_img, train_set.classes[label_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI64Ik9tkLZ"
      },
      "source": [
        "### Capa 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsPTz6ltkLa",
        "outputId": "8792462c-9e77-486e-8e3a-491b0636d962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 1 **************************\n",
            "Dimensiones de entrada: 299 x 299\n",
            "Número de canales de entrada: 3\n",
            "Número de filtros: 32\n",
            "Dimensiones del kernel: 3 x 3\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 150 x 150\n",
            "Dimensiones luego del MaxPool2d: 75\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 1 **************************')\n",
        "layer1_in_channels, layer1_img_width, layer1_img_height = tensor_img.shape\n",
        "print(\"Dimensiones de entrada:\", layer1_img_width, \"x\", layer1_img_height)\n",
        "print(\"Número de canales de entrada:\", layer1_in_channels)\n",
        "\n",
        "layer1_num_filters = 32\n",
        "print(\"Número de filtros:\", layer1_num_filters)\n",
        "\n",
        "layer1_kernel_size = 3\n",
        "print(\"Dimensiones del kernel:\", layer1_kernel_size, \"x\", layer1_kernel_size)\n",
        "\n",
        "layer1_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer1_stride)\n",
        "\n",
        "layer1_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer1_padding)\n",
        "\n",
        "layer1_out_size = utils.size_output_layer(layer1_img_width, layer1_kernel_size, layer1_stride, layer1_padding)\n",
        "print(\"Dimensiones de salida:\", layer1_out_size, \"x\", layer1_out_size)\n",
        "\n",
        "layer1_output_dim = utils.size_output_layer(layer1_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer1_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUFBWQS4tkLb"
      },
      "outputs": [],
      "source": [
        "layer1_conv = nn.Conv2d(\n",
        "        layer1_in_channels,\n",
        "        layer1_num_filters,\n",
        "        layer1_kernel_size,\n",
        "        layer1_stride,\n",
        "        layer1_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpXwZfmtkLe"
      },
      "source": [
        "### Capa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxv5xj4tkLe",
        "outputId": "0c9010c0-a6cd-4c9b-9eb7-de4dc56c936a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 2 **************************\n",
            "Dimensiones de entrada: 75 x 75\n",
            "Número de canales de entrada: 32\n",
            "Número de filtros: 64\n",
            "Dimensiones del kernel: 2 x 2\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 38 x 38\n",
            "Dimensiones luego del MaxPool2d: 19\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 2 **************************')\n",
        "layer2_in_channels, layer2_img_width, layer2_img_height = layer1_num_filters, layer1_output_dim, layer1_output_dim\n",
        "print(\"Dimensiones de entrada:\", layer2_img_width, \"x\", layer2_img_height)\n",
        "print(\"Número de canales de entrada:\", layer2_in_channels)\n",
        "\n",
        "layer2_num_filters = 64\n",
        "print(\"Número de filtros:\", layer2_num_filters)\n",
        "\n",
        "layer2_kernel_size = 2\n",
        "print(\"Dimensiones del kernel:\", layer2_kernel_size, \"x\", layer2_kernel_size)\n",
        "\n",
        "layer2_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer2_stride)\n",
        "\n",
        "layer2_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer2_padding)\n",
        "\n",
        "layer2_out_size = utils.size_output_layer(layer2_img_width, layer2_kernel_size, layer2_stride, layer2_padding)\n",
        "print(\"Dimensiones de salida:\", layer2_out_size, \"x\", layer2_out_size)\n",
        "\n",
        "layer2_output_dim = utils.size_output_layer(layer2_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer2_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iKeohOJtkLf"
      },
      "outputs": [],
      "source": [
        "layer2_conv = nn.Conv2d(\n",
        "        layer2_in_channels,\n",
        "        layer2_num_filters,\n",
        "        layer2_kernel_size,\n",
        "        layer2_stride,\n",
        "        layer2_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS5CVeBtkLf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8XPq7tkLf",
        "outputId": "90b20eb1-9cc6-4a83-f0fd-620b92488c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.2, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 1: Convolutional layer\n",
        "layer1 = nn.Sequential(\n",
        "    layer1_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer1_num_filters),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWRAnEatkLg",
        "outputId": "9a347a4c-b561-43bb-bdf2-a47cac23b5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 2: Convolutional layer\n",
        "layer2 = nn.Sequential(\n",
        "    layer2_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer2_num_filters),\n",
        "    nn.Dropout(p=0.1),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WgzVKfCvtkLg"
      },
      "outputs": [],
      "source": [
        "# Layer 3: Linear Classifier\n",
        "num_classes = 4\n",
        "classifier = nn.Linear(\n",
        "    in_features=layer2_output_dim * layer2_output_dim * layer2_num_filters,\n",
        "    out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L-JabGrFtkLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.2, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = utils.CNN()\n",
        "\n",
        "model.addLayer(layer1)\n",
        "model.addLayer(layer2)\n",
        "\n",
        "model.addClassifier(classifier)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate =  0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXyqLR-otkLh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNv67NEjtkLh",
        "outputId": "4f7807b6-eb6e-4d9c-b560-a53a1db39eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch [1/10], Step [100/232], Loss: 0.8311\n",
            "Epoch [1/10], Step [200/232], Loss: 0.5074\n",
            "Epoch [2/10], Step [100/232], Loss: 0.5045\n",
            "Epoch [2/10], Step [200/232], Loss: 1.0275\n",
            "Epoch [3/10], Step [100/232], Loss: 0.5282\n",
            "Epoch [3/10], Step [200/232], Loss: 0.7050\n",
            "Epoch [4/10], Step [100/232], Loss: 0.8011\n",
            "Epoch [4/10], Step [200/232], Loss: 0.3252\n",
            "Epoch [5/10], Step [100/232], Loss: 0.5021\n",
            "Epoch [5/10], Step [200/232], Loss: 0.3499\n",
            "Epoch [6/10], Step [100/232], Loss: 0.3181\n",
            "Epoch [6/10], Step [200/232], Loss: 0.1531\n",
            "Epoch [7/10], Step [100/232], Loss: 0.4625\n",
            "Epoch [7/10], Step [200/232], Loss: 0.3554\n",
            "Epoch [8/10], Step [100/232], Loss: 0.1986\n",
            "Epoch [8/10], Step [200/232], Loss: 0.2772\n",
            "Epoch [9/10], Step [100/232], Loss: 0.3417\n",
            "Epoch [9/10], Step [200/232], Loss: 0.2297\n",
            "Epoch [10/10], Step [100/232], Loss: 0.2943\n",
            "Epoch [10/10], Step [200/232], Loss: 0.1716\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "list_loss= []\n",
        "list_time = []\n",
        "j=0\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # change the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_loss.append(loss.item())\n",
        "        list_time.append(j)\n",
        "        j+=1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IWy5Pl4LtkLi",
        "outputId": "125c47db-de59-4d7c-c841-d1f867247562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faa64ab9090>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(list_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Mymj_tkLi",
        "outputId": "c5fd750c-f1df-4c9e-af47-427cc14a2fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 86.10586011342156 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "        t_outputs = model(t_images)\n",
        "        _, predicted = torch.max(t_outputs.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (predicted == t_labels).sum().item()\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c836ea1838598e769062a9cf5fa60bfd2e0efc946eee0512711b4e28a236389"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
