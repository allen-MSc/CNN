{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 8\n",
        "Applying **transforms.Grayscale()** to Dataset\n",
        "```\n",
        "CNN(\n",
        "  (layers): ModuleList(\n",
        "    (0): Sequential(\n",
        "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.2, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (1): Sequential(\n",
        "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "  )\n",
        "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "### Accuracy: 85.91682419659735 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UYZ8OLBDx-Ux"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip install --force-reinstall numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MuUh8kvMtkLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hts90WGtkLY",
        "outputId": "360e9580-57cc-4c49-df7a-026f80e01b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya existen datos de train, test y val.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = os.path.abspath('dataset_kagle/COVID-19_Radiography_Dataset')\n",
        "dest_dir = os.path.abspath('dataset')\n",
        "\n",
        "train_dir, test_dir, val_dir = utils.split_dataset(dataset_dir, dest_dir, test_ratio=0.2, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgR13YFtkLZ",
        "outputId": "05921b66-384a-4694-8d69-e7d66c1787c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 14814\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4232\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "transformers = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1), # returned image is single channel\n",
        "  transforms.ToTensor() # transform.ToTensor() will make the pixel values to be between [0, 1]\n",
        "])\n",
        "\n",
        "train_set =  torchvision.datasets.ImageFolder(train_dir, transformers)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "test_set =  torchvision.datasets.ImageFolder(test_dir, transformers)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_bKkikd4tkLZ"
      },
      "outputs": [],
      "source": [
        "tensor_img, label_idx = train_set[0]\n",
        "#utils.show_img(tensor_img, train_set.classes[label_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI64Ik9tkLZ"
      },
      "source": [
        "### Capa 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsPTz6ltkLa",
        "outputId": "0896b64c-96b1-402e-dcc2-9e1c1ec68a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 1 **************************\n",
            "Dimensiones de entrada: 299 x 299\n",
            "Número de canales de entrada: 1\n",
            "Número de filtros: 32\n",
            "Dimensiones del kernel: 3 x 3\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 150 x 150\n",
            "Dimensiones luego del MaxPool2d: 75\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 1 **************************')\n",
        "layer1_in_channels, layer1_img_width, layer1_img_height = tensor_img.shape\n",
        "print(\"Dimensiones de entrada:\", layer1_img_width, \"x\", layer1_img_height)\n",
        "print(\"Número de canales de entrada:\", layer1_in_channels)\n",
        "\n",
        "layer1_num_filters = 32\n",
        "print(\"Número de filtros:\", layer1_num_filters)\n",
        "\n",
        "layer1_kernel_size = 3\n",
        "print(\"Dimensiones del kernel:\", layer1_kernel_size, \"x\", layer1_kernel_size)\n",
        "\n",
        "layer1_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer1_stride)\n",
        "\n",
        "layer1_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer1_padding)\n",
        "\n",
        "layer1_out_size = utils.size_output_layer(layer1_img_width, layer1_kernel_size, layer1_stride, layer1_padding)\n",
        "print(\"Dimensiones de salida:\", layer1_out_size, \"x\", layer1_out_size)\n",
        "\n",
        "layer1_output_dim = utils.size_output_layer(layer1_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer1_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUFBWQS4tkLb"
      },
      "outputs": [],
      "source": [
        "layer1_conv = nn.Conv2d(\n",
        "        layer1_in_channels,\n",
        "        layer1_num_filters,\n",
        "        layer1_kernel_size,\n",
        "        layer1_stride,\n",
        "        layer1_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpXwZfmtkLe"
      },
      "source": [
        "### Capa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxv5xj4tkLe",
        "outputId": "eb89a404-1e3a-46bb-f223-0eb5a54d3463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 2 **************************\n",
            "Dimensiones de entrada: 75 x 75\n",
            "Número de canales de entrada: 32\n",
            "Número de filtros: 64\n",
            "Dimensiones del kernel: 2 x 2\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 38 x 38\n",
            "Dimensiones luego del MaxPool2d: 19\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 2 **************************')\n",
        "layer2_in_channels, layer2_img_width, layer2_img_height = layer1_num_filters, layer1_output_dim, layer1_output_dim\n",
        "print(\"Dimensiones de entrada:\", layer2_img_width, \"x\", layer2_img_height)\n",
        "print(\"Número de canales de entrada:\", layer2_in_channels)\n",
        "\n",
        "layer2_num_filters = 64\n",
        "print(\"Número de filtros:\", layer2_num_filters)\n",
        "\n",
        "layer2_kernel_size = 2\n",
        "print(\"Dimensiones del kernel:\", layer2_kernel_size, \"x\", layer2_kernel_size)\n",
        "\n",
        "layer2_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer2_stride)\n",
        "\n",
        "layer2_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer2_padding)\n",
        "\n",
        "layer2_out_size = utils.size_output_layer(layer2_img_width, layer2_kernel_size, layer2_stride, layer2_padding)\n",
        "print(\"Dimensiones de salida:\", layer2_out_size, \"x\", layer2_out_size)\n",
        "\n",
        "layer2_output_dim = utils.size_output_layer(layer2_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer2_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iKeohOJtkLf"
      },
      "outputs": [],
      "source": [
        "layer2_conv = nn.Conv2d(\n",
        "        layer2_in_channels,\n",
        "        layer2_num_filters,\n",
        "        layer2_kernel_size,\n",
        "        layer2_stride,\n",
        "        layer2_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS5CVeBtkLf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8XPq7tkLf",
        "outputId": "2c42f489-c781-4305-cf07-3b190fb593e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.2, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 1: Convolutional layer\n",
        "layer1 = nn.Sequential(\n",
        "    layer1_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer1_num_filters),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWRAnEatkLg",
        "outputId": "8d2ae257-d7e1-4363-b7c3-18e4967eee3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 2: Convolutional layer\n",
        "layer2 = nn.Sequential(\n",
        "    layer2_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WgzVKfCvtkLg"
      },
      "outputs": [],
      "source": [
        "# Layer 3: Linear Classifier\n",
        "num_classes = 4\n",
        "classifier = nn.Linear(\n",
        "    in_features=layer2_output_dim * layer2_output_dim * layer2_num_filters,\n",
        "    out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L-JabGrFtkLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.2, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = utils.CNN()\n",
        "\n",
        "model.addLayer(layer1)\n",
        "model.addLayer(layer2)\n",
        "\n",
        "model.addClassifier(classifier)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate =  0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXyqLR-otkLh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNv67NEjtkLh",
        "outputId": "7d9b19ec-7c02-4eb3-f5cc-e561c164d08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch [1/10], Step [100/232], Loss: 0.7123\n",
            "Epoch [1/10], Step [200/232], Loss: 0.4410\n",
            "Epoch [2/10], Step [100/232], Loss: 0.4895\n",
            "Epoch [2/10], Step [200/232], Loss: 0.5045\n",
            "Epoch [3/10], Step [100/232], Loss: 0.3641\n",
            "Epoch [3/10], Step [200/232], Loss: 0.4154\n",
            "Epoch [4/10], Step [100/232], Loss: 0.2315\n",
            "Epoch [4/10], Step [200/232], Loss: 0.2878\n",
            "Epoch [5/10], Step [100/232], Loss: 0.1684\n",
            "Epoch [5/10], Step [200/232], Loss: 0.1875\n",
            "Epoch [6/10], Step [100/232], Loss: 0.1495\n",
            "Epoch [6/10], Step [200/232], Loss: 0.2973\n",
            "Epoch [7/10], Step [100/232], Loss: 0.0720\n",
            "Epoch [7/10], Step [200/232], Loss: 0.1781\n",
            "Epoch [8/10], Step [100/232], Loss: 0.1688\n",
            "Epoch [8/10], Step [200/232], Loss: 0.1822\n",
            "Epoch [9/10], Step [100/232], Loss: 0.0628\n",
            "Epoch [9/10], Step [200/232], Loss: 0.1264\n",
            "Epoch [10/10], Step [100/232], Loss: 0.1738\n",
            "Epoch [10/10], Step [200/232], Loss: 0.0394\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "list_loss= []\n",
        "list_time = []\n",
        "j=0\n",
        "total_steps = len(train_loader)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # change the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_loss.append(loss.item())\n",
        "        list_time.append(j)\n",
        "        j+=1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IWy5Pl4LtkLi",
        "outputId": "8e2a9483-9cbd-405e-acb8-fc977ebce5ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f71298cfc50>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(list_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Mymj_tkLi",
        "outputId": "b8e2cc3f-61b0-41b7-f68c-a2032a562477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 85.91682419659735 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "        t_outputs = model(t_images)\n",
        "        _, predicted = torch.max(t_outputs.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (predicted == t_labels).sum().item()\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c836ea1838598e769062a9cf5fa60bfd2e0efc946eee0512711b4e28a236389"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
