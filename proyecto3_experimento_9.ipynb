{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 9\n",
        "Applying **transforms.Grayscale()** to Dataset\n",
        "```\n",
        "CNN(\n",
        "  (layers): ModuleList(\n",
        "    (0): Sequential(\n",
        "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (3): Dropout(p=0.2, inplace=False)\n",
        "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (1): Sequential(\n",
        "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
        "      (1): ReLU()\n",
        "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "  )\n",
        "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "### Accuracy: 85.79867674858222 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UYZ8OLBDx-Ux"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip install --force-reinstall numpy==1.19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MuUh8kvMtkLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hts90WGtkLY",
        "outputId": "13066dd0-f17c-4684-fef5-b661474089e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya existen datos de train, test y val.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = os.path.abspath('dataset_kagle/COVID-19_Radiography_Dataset')\n",
        "dest_dir = os.path.abspath('dataset')\n",
        "\n",
        "train_dir, test_dir, val_dir = utils.split_dataset(dataset_dir, dest_dir, test_ratio=0.2, val_ratio=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgR13YFtkLZ",
        "outputId": "832a7912-0fbc-4ec7-dad2-e52037cdcf41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 14814\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 4232\n",
            "    Root location: /Users/allen/Documents/Msc/Semestre II/Aprendizaje Automatico/proyecto3/dataset/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "transformers = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=1), # returned image is single channel\n",
        "  transforms.ToTensor(), # transform.ToTensor() will make the pixel values to be between [0, 1]\n",
        "  transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "])\n",
        "\n",
        "train_set =  torchvision.datasets.ImageFolder(train_dir, transformers)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(train_set)\n",
        "\n",
        "test_set =  torchvision.datasets.ImageFolder(test_dir, transformers)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_bKkikd4tkLZ"
      },
      "outputs": [],
      "source": [
        "tensor_img, label_idx = train_set[0]\n",
        "#utils.show_img(tensor_img, train_set.classes[label_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdI64Ik9tkLZ"
      },
      "source": [
        "### Capa 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HsPTz6ltkLa",
        "outputId": "2ba4cd8c-e1e7-43d9-aa7a-6f1f8f9b4018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 1 **************************\n",
            "Dimensiones de entrada: 299 x 299\n",
            "Número de canales de entrada: 1\n",
            "Número de filtros: 32\n",
            "Dimensiones del kernel: 3 x 3\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 150 x 150\n",
            "Dimensiones luego del MaxPool2d: 75\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 1 **************************')\n",
        "layer1_in_channels, layer1_img_width, layer1_img_height = tensor_img.shape\n",
        "print(\"Dimensiones de entrada:\", layer1_img_width, \"x\", layer1_img_height)\n",
        "print(\"Número de canales de entrada:\", layer1_in_channels)\n",
        "\n",
        "layer1_num_filters = 32\n",
        "print(\"Número de filtros:\", layer1_num_filters)\n",
        "\n",
        "layer1_kernel_size = 3\n",
        "print(\"Dimensiones del kernel:\", layer1_kernel_size, \"x\", layer1_kernel_size)\n",
        "\n",
        "layer1_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer1_stride)\n",
        "\n",
        "layer1_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer1_padding)\n",
        "\n",
        "layer1_out_size = utils.size_output_layer(layer1_img_width, layer1_kernel_size, layer1_stride, layer1_padding)\n",
        "print(\"Dimensiones de salida:\", layer1_out_size, \"x\", layer1_out_size)\n",
        "\n",
        "layer1_output_dim = utils.size_output_layer(layer1_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer1_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lUFBWQS4tkLb"
      },
      "outputs": [],
      "source": [
        "layer1_conv = nn.Conv2d(\n",
        "        layer1_in_channels,\n",
        "        layer1_num_filters,\n",
        "        layer1_kernel_size,\n",
        "        layer1_stride,\n",
        "        layer1_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpXwZfmtkLe"
      },
      "source": [
        "### Capa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxv5xj4tkLe",
        "outputId": "608df22b-ff1e-408a-b716-7794191f1795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************** Info Layer 2 **************************\n",
            "Dimensiones de entrada: 75 x 75\n",
            "Número de canales de entrada: 32\n",
            "Número de filtros: 64\n",
            "Dimensiones del kernel: 2 x 2\n",
            "Tamaño de Stride: 2\n",
            "Tamaño de Padding: 1\n",
            "Dimensiones de salida: 38 x 38\n",
            "Dimensiones luego del MaxPool2d: 19\n"
          ]
        }
      ],
      "source": [
        "print('****************** Info Layer 2 **************************')\n",
        "layer2_in_channels, layer2_img_width, layer2_img_height = layer1_num_filters, layer1_output_dim, layer1_output_dim\n",
        "print(\"Dimensiones de entrada:\", layer2_img_width, \"x\", layer2_img_height)\n",
        "print(\"Número de canales de entrada:\", layer2_in_channels)\n",
        "\n",
        "layer2_num_filters = 64\n",
        "print(\"Número de filtros:\", layer2_num_filters)\n",
        "\n",
        "layer2_kernel_size = 2\n",
        "print(\"Dimensiones del kernel:\", layer2_kernel_size, \"x\", layer2_kernel_size)\n",
        "\n",
        "layer2_stride = 2\n",
        "print(\"Tamaño de Stride:\", layer2_stride)\n",
        "\n",
        "layer2_padding = 1\n",
        "print(\"Tamaño de Padding:\", layer2_padding)\n",
        "\n",
        "layer2_out_size = utils.size_output_layer(layer2_img_width, layer2_kernel_size, layer2_stride, layer2_padding)\n",
        "print(\"Dimensiones de salida:\", layer2_out_size, \"x\", layer2_out_size)\n",
        "\n",
        "layer2_output_dim = utils.size_output_layer(layer2_out_size, 2, 2, 0)\n",
        "print(\"Dimensiones luego del MaxPool2d:\", layer2_output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1iKeohOJtkLf"
      },
      "outputs": [],
      "source": [
        "layer2_conv = nn.Conv2d(\n",
        "        layer2_in_channels,\n",
        "        layer2_num_filters,\n",
        "        layer2_kernel_size,\n",
        "        layer2_stride,\n",
        "        layer2_padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS5CVeBtkLf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8XPq7tkLf",
        "outputId": "c5e83019-f166-48c2-92ba-6378a2be9927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Dropout(p=0.2, inplace=False)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 1: Convolutional layer\n",
        "layer1 = nn.Sequential(\n",
        "    layer1_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(layer1_num_filters),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWRAnEatkLg",
        "outputId": "930a5892-c546-4c0f-cb67-e0d20642066c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Layer 2: Convolutional layer\n",
        "layer2 = nn.Sequential(\n",
        "    layer2_conv,\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")\n",
        "print(layer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WgzVKfCvtkLg"
      },
      "outputs": [],
      "source": [
        "# Layer 3: Linear Classifier\n",
        "num_classes = 4\n",
        "classifier = nn.Linear(\n",
        "    in_features=layer2_output_dim * layer2_output_dim * layer2_num_filters,\n",
        "    out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L-JabGrFtkLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.2, inplace=False)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=23104, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = utils.CNN()\n",
        "\n",
        "model.addLayer(layer1)\n",
        "model.addLayer(layer2)\n",
        "\n",
        "model.addClassifier(classifier)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate =  0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXyqLR-otkLh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNv67NEjtkLh",
        "outputId": "a0444659-33c0-406e-af04-64411e1b3d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch [1/10], Step [100/232], Loss: 0.4942\n",
            "Epoch [1/10], Step [200/232], Loss: 0.6179\n",
            "Epoch [2/10], Step [100/232], Loss: 0.2894\n",
            "Epoch [2/10], Step [200/232], Loss: 0.3025\n",
            "Epoch [3/10], Step [100/232], Loss: 0.2492\n",
            "Epoch [3/10], Step [200/232], Loss: 0.4538\n",
            "Epoch [4/10], Step [100/232], Loss: 0.1817\n",
            "Epoch [4/10], Step [200/232], Loss: 0.2100\n",
            "Epoch [5/10], Step [100/232], Loss: 0.2287\n",
            "Epoch [5/10], Step [200/232], Loss: 0.3751\n",
            "Epoch [6/10], Step [100/232], Loss: 0.1639\n",
            "Epoch [6/10], Step [200/232], Loss: 0.1201\n",
            "Epoch [7/10], Step [100/232], Loss: 0.2229\n",
            "Epoch [7/10], Step [200/232], Loss: 0.2194\n",
            "Epoch [8/10], Step [100/232], Loss: 0.0849\n",
            "Epoch [8/10], Step [200/232], Loss: 0.1786\n",
            "Epoch [9/10], Step [100/232], Loss: 0.1129\n",
            "Epoch [9/10], Step [200/232], Loss: 0.2023\n",
            "Epoch [10/10], Step [100/232], Loss: 0.2536\n",
            "Epoch [10/10], Step [200/232], Loss: 0.1496\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "list_loss= []\n",
        "list_time = []\n",
        "j=0\n",
        "total_steps = len(train_loader)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # change the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        list_loss.append(loss.item())\n",
        "        list_time.append(j)\n",
        "        j+=1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "IWy5Pl4LtkLi",
        "outputId": "18379e78-feb6-4088-e1ea-4552f12547bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff1196276d0>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(list_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Mymj_tkLi",
        "outputId": "9b399c8c-573c-48c0-a750-cc5fe32cdade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 85.79867674858222 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for t_images, t_labels in test_loader:\n",
        "        t_images = t_images.to(device)\n",
        "        t_labels = t_labels.to(device)\n",
        "        t_outputs = model(t_images)\n",
        "        _, predicted = torch.max(t_outputs.data, 1)\n",
        "        total += t_labels.size(0)\n",
        "        correct += (predicted == t_labels).sum().item()\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "proyecto3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c836ea1838598e769062a9cf5fa60bfd2e0efc946eee0512711b4e28a236389"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
